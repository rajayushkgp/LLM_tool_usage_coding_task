{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from inference_utils import P1_inferecening, P2_P3_inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1 Pipeline Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for Static Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"../resources/P1_datasets/p1_static_dataset.csv\")\n",
    "model = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "\n",
    "if not os.path.exists('../output/P1_infered_output'):\n",
    "    os.makedirs('../output/P1_infered_output')\n",
    "\n",
    "static_output = []\n",
    "P1_inferencing_for_Static = P1_inferecening()\n",
    "for i, row in static_df.iterrows():\n",
    "    static_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],\n",
    "                   'docstring': row['Docstring']}\n",
    "    ans, latency = P1_inferencing_for_Static.completionP1StaticDynamic(model,static_dict)\n",
    "    static_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P1_infered_output/staticInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(static_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for Dynamic Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_df = pd.read_csv(\"../resources/P1_datasets/p1_dynamic_dataset.csv\")\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "\n",
    "if not os.path.exists('../output/P1_infered_output'):\n",
    "    os.makedirs('../output/P1_infered_output')\n",
    "\n",
    "dynamic_output = []\n",
    "P1_inferencing_for_dynamic =P1_inferecening()\n",
    "for i, row in dynamic_df.iterrows():\n",
    "    dynamic_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],\n",
    "                   'docstring': row['Docstring']}\n",
    "    ans, latency = P1_inferencing_for_dynamic.completionP1StaticDynamic(model, dynamic_dict)\n",
    "    dynamic_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P1_infered_output/dynamicInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dynamic_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for Bonus Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_df = pd.read_csv(\"../resources/P1_datasets/p1_bonus_dataset.csv\")\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "\n",
    "if not os.path.exists('../output/P1_infered_output'):\n",
    "    os.makedirs('../output/P1_infered_output')\n",
    "\n",
    "bonus_output = []\n",
    "P1_inferencing_for_bonus = P1_inferecening()\n",
    "for i, row in bonus_df.iterrows():\n",
    "    bonus_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],\n",
    "                   'docstring': row['Docstring']}\n",
    "    ans, latency = P1_inferencing_for_bonus.completionP1Bonus(model_name,bonus_dict)\n",
    "    bonus_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P1_infered_output/bonusInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(bonus_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for Modified Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_df = pd.read_csv(\"../resources/P1_datasets/p1_modified_dataset.csv\")\n",
    "model_name = \"deepseek-ai/deepseek-coder-1.3b-instruct\"\n",
    "\n",
    "if not os.path.exists('../output/P1_infered_output'):\n",
    "    os.makedirs('../output/P1_infered_output')\n",
    "\n",
    "modified_output = []\n",
    "P1_inferencing_for_modified = P1_inferecening()\n",
    "for i, row in modified_df.iterrows():\n",
    "    modified_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],\n",
    "                   'docstring': row['Docstring']}\n",
    "    ans, latency = P1_inferencing_for_modified.completionP1Modified(model_name,modified_dict)\n",
    "    modified_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P1_infered_output/modifiedInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(modified_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for P2 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For static dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"../resources/P2_datasets/p2_static_dataset_test.csv\")\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "infer_model = \"Insight244/codellama-p3-data-no-dynamic-no-random-no-bonus\"\n",
    "\n",
    "if not os.path.exists('../output/P2_infered_output'):\n",
    "    os.makedirs('../output/P2_infered_output')\n",
    "\n",
    "P2_inferencing_for_Static = P2_P3_inferencing()\n",
    "P2_inferencing_for_Static.P2_P3_load_model(model_name, infer_model)\n",
    "\n",
    "static_output = []\n",
    "\n",
    "for i, row in static_df.iterrows():\n",
    "    static_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],}\n",
    "    \n",
    "    ans, latency = P2_inferencing_for_Static.P2_P3_get_inference(static_dict)\n",
    "\n",
    "    static_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P2_infered_output/staticInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(static_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for dynamic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_df = pd.read_csv(\"../resources/P2_datasets/p2_dynamic_dataset_test.csv\")\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "infer_model = \"Insight244/codellama-p3-data-no-dynamic-no-random-no-bonus\"\n",
    "\n",
    "if not os.path.exists('../output/P2_infered_output'):\n",
    "    os.makedirs('../output/P2_infered_output')\n",
    "\n",
    "P2_inferencing_for_dynamic = P2_P3_inferencing()\n",
    "P2_inferencing_for_dynamic.P2_P3_load_model(model_name, infer_model)\n",
    "\n",
    "dynamic_output = []\n",
    "\n",
    "for i, row in dynamic_df.iterrows():\n",
    "    dynamic_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],}\n",
    "\n",
    "    ans, latency = P2_inferencing_for_dynamic.P2_P3_get_inference(dynamic_dict)\n",
    "\n",
    "    dynamic_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P2_infered_output/dynamicInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dynamic_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for bonus dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_df = pd.read_csv(\"../resources/P2_datasets/p2_bonus_dataset_test.csv\")\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "infer_model = \"Insight244/codellama-p3-data-no-dynamic-no-random-no-bonus\"\n",
    "\n",
    "if not os.path.exists('../output/P2_infered_output'):\n",
    "    os.makedirs('../output/P2_infered_output')\n",
    "\n",
    "P2_inferencing_for_bonus = P2_P3_inferencing()\n",
    "P2_inferencing_for_bonus.P2_P3_load_model(model_name, infer_model)\n",
    "\n",
    "bonus_output = []\n",
    "\n",
    "for i, row in bonus_df.iterrows():\n",
    "    bonus_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],}\n",
    "\n",
    "    ans, latency = P2_inferencing_for_bonus.P2_P3_get_inference(bonus_dict)\n",
    "\n",
    "    bonus_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P2_infered_output/bonusInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(bonus_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for P3 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For static dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = pd.read_csv(\"../resources/P3_datasets/p3_static_dataset_test.csv\")\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "infer_model = \"Insight244/codellama-p3-data-no-dynamic-no-random-no-bonus\"\n",
    "\n",
    "if not os.path.exists('../output/P3_infered_output'):\n",
    "    os.makedirs('../output/P3_infered_output')\n",
    "\n",
    "P3_inferencing_for_Static = P2_P3_inferencing()\n",
    "P3_inferencing_for_Static.P2_P3_load_model(model_name, infer_model)\n",
    "\n",
    "static_output = []\n",
    "\n",
    "for i, row in static_df.iterrows():\n",
    "    static_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],}\n",
    "\n",
    "    ans, latency = P3_inferencing_for_Static.P2_P3_get_inference(static_dict)\n",
    "\n",
    "    static_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P3_infered_output/staticInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(static_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for dynamic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_df = pd.read_csv(\"../resources/P3_datasets/p3_dynamic_dataset_test.csv\")\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "infer_model = \"Insight244/codellama-p3-data-no-dynamic-no-random-no-bonus\"\n",
    "\n",
    "if not os.path.exists('../output/P3_infered_output'):\n",
    "    os.makedirs('../output/P3_infered_output')\n",
    "\n",
    "P3_inferencing_for_dynamic = P2_P3_inferencing()\n",
    "P3_inferencing_for_dynamic.P2_P3_load_model(model_name, infer_model)\n",
    "\n",
    "dynamic_output = []\n",
    "\n",
    "for i, row in dynamic_df.iterrows():\n",
    "    dynamic_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],}\n",
    "\n",
    "    ans, latency = P3_inferencing_for_dynamic.P2_P3_get_inference(dynamic_dict)\n",
    "\n",
    "    dynamic_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P3_infered_output/dynamicInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(dynamic_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for bonus dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_df = pd.read_csv(\"../resources/P3_datasets/p3_bonus_dataset_test.csv\")\n",
    "\n",
    "model_name = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "infer_model = \"Insight244/codellama-p3-data-no-dynamic-no-random-no-bonus\"\n",
    "\n",
    "if not os.path.exists('../output/P3_infered_output'):\n",
    "    os.makedirs('../output/P3_infered_output')\n",
    "\n",
    "P3_inferencing_for_bonus = P2_P3_inferencing()\n",
    "P3_inferencing_for_bonus.P2_P3_load_model(model_name, infer_model)\n",
    "\n",
    "bonus_output = []\n",
    "\n",
    "for i, row in bonus_df.iterrows():\n",
    "    bonus_dict = {'query': row['Query'],\n",
    "                   'output': row['Output'],}\n",
    "\n",
    "    ans, latency = P3_inferencing_for_bonus.P2_P3_get_inference(bonus_dict)\n",
    "\n",
    "    bonus_output.append({'Output': ans , 'Latency': latency})\n",
    "\n",
    "field_names= ['Output','Latency']\n",
    "\n",
    "with open('../output/P3_infered_output/bonusInference.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(bonus_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devrev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
